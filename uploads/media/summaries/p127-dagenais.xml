<?xml version="1.0" encoding="UTF-8" ?><root><INTRODUCTION type="str">For example, hundreds of applications like Google Code Search and Twitter use the JQuery framework to pro- vide an interactive user experience with Javascript and AJAX. Creating and main- taining this documentation potentially represents a large ef- fort yet we do not know the kind of problems documentation contributors encounter, the factors they consider when work- ing on the documentation and the impact their documentation- related decisions have on the project. Specif- ically, we were interested in identifying the documentation decisions made by open source contributors, the context in which these decisions were made, and the consequences these decisions had on the project. We performed semi-structured interviews with 22 developers or technical writers who wrote or read the documentation of open source projects. In par- allel, we manually inspected more than 1500 revisions of 19 documents selected from 10 open source projects. </INTRODUCTION><METHOD type="str">Grounded theory is a qualitative research methodology that employs theoretical sampling and open coding to formulate a theory &quot;grounded&quot; in the empirical data. By following grounded theory, we started from general research questions and refined the ques- tions, and the data collection instruments, as the study pro- gressed. For example, after having interviewed two contributors of Perl projects, we filtered out further Perl projects; after hav- ing interviewed four contributors from library projects, we sent more invitations to contributors of framework projects. Although all reported observations are linked to specific cataloged evidences, we elide some of these links for the sake of brevity. Our method follows that of previous software engineering studies based on grounded theory . </METHOD><Data_Collection type="str">The projects of the contributors, the users, and the his- torical analysis were selected in parallel so they are not nec- essarily the same. We used this strategy to preserve the anonymity of the contributors and to allow us to provide concrete examples by naming real open source projects when discussing observations from the users&apos; interviews and the historical analysis. To recruit contributors, we began by making a list of open source projects that were still being used by a community of users and that were large enough to require documentation to be used. We systematically analyzed the evolution of documents of open source projects that maintained their documentation in a source repository (e.g., CVS) or in a wiki. We also used the same criteria as for the contributors to select projects for our historical analysis. </Data_Collection><CONCEPTUAL_FRAMEWORK type="str">Following the analysis of the interviews and the document revisions, we identified three production modes in which doc- umentation of open source projects is created. Although we expected documentation to be produced in different modes, the study helped us concretize what these modes were and what they corresponded to in practice. Sometimes, major documen- tation tasks such as the writing of a book on the project requires a burst of documentation effort. This paper focuses on the relationships between the decisions, their factors, and their consequences. For example, for the decision point &quot;When to adapt the documentation to the project&apos;s evolution&quot;, there are many possible decisions (e.g., updating the documentation shortly after making a change, before an official release, before mak- ing a change, etc.). </CONCEPTUAL_FRAMEWORK><DECISIONS type="str">There are three main types of infrastructure that are used by contributors, sometimes in combination with each other: wikis (see Section 4.1), documentation suites (e.g., POD, Sphinx, or Javadoc), and general documents such as HTML. Small and continuous incremen- tal changes are the main force driving the evolution of open source project documentation. In this production mode, open source contributors encounter two major decision points: how to adapt the documentation to the project&apos;s evolution and how to manage the project community&apos;s contributions. Managing the documentation contributions represents a large fraction of the documentation effort: in our historical analysis, we found that 28% of the document revisions, excluding docu- ments on wikis, originated from the community. Because books about open source projects are not always updated, their main advan- tage lies in the improvement of the quality of the official documentation and the time that the contributors take to reflect on their design decisions. </DECISIONS><Wiki_as_Documentation_Infrastructure type="str">Contributors select wikis to host their documen- tation when the programming language of the project is not associated with any infrastructure (such as CPAN with Perl) or when the project contributors want to rely on crowdsourc- ing to create documentation, i.e., they hope that users will create and manage the documentation. Indeed, we observed in our historical analysis that projects on wikis are often plagued by SPAM (24.1% of the revisions in Firefox) or by the addition of URLs that do not add any valuable content to the documentation (e.g., a link to a tutorial in a list already containing 20 links). Another problem with wikis is that they lack authorita- tiveness, an important issue according to our users: &quot;I don&apos;t want to look at a wiki that might be outdated or incorrect&quot;U3 For example, we observed cases such as a revision in a Fire- fox tutorial where one line of a code example was erroneously modified (possibly in good faith). As users and contributors mentioned, the community is less inclined to contribute documentation than it is to contribute code, so the barrier to contribute docu- mentation must be lower than the barrier to contribute code. For example, we observed in our historical analysis that Django provides a series of links to ask a question or to report an issue with the documentation on every page. </Wiki_as_Documentation_Infrastructure><Getting_Started_as_Initial_Documentation type="str">Context. Contrib- utor C8 mentioned that for open source projects, getting started documentation is the best kind of documentation to start with because once a user knows how to use the basic features, it is possible to look at the source code to learn the details of the API. In con- trast, the contributors of the five oldest projects reported that there was no marketing purpose behind the getting started documentation: these projects were the first to be released in their respective field and the contributors wrote the documentation for learning purpose only. Contributors of libraries that offer atomic functions that do not interact with each other felt that getting started documentation was difficult to create because no reasonable code snippet could give an idea of the range of features of- fered by the libraries. Consequences. </Getting_Started_as_Initial_Documentation><Reference_Documentation_as_Initial_Documentation type="str">When a library offers mostly atomic functions, reference documentation is the most appropriate documen- tation type to begin with because, as contributor C11 men- tioned, it can be difficult to create getting started documen- tation that shows examples calling many functions. In contrast to libraries with atomic functions, frameworks expecting users to extend and use the framework in some specific ways need more than reference documentation ac- cording to the users we interviewed. Frameworks, by their nature, require users to compose many parts together, but reference documentation only focuses on one part at the time: &quot;interactions between these classes is often very dif- ficult to get a grasp of... you need more information how the overall structure of the framework works&quot;U4. When contributors initially create the reference documen- tation, they either systematically document all parts of their projects or they rely on a more pragmatic approach: &quot;I try to go for anything that is not obvious&quot;C10. For weakly and statically typed languages such as C, developers cannot rely on type names (because many types are integer pointers) or on an facilities provided by an interpreter and reference documentation becomes more important. </Reference_Documentation_as_Initial_Documentation><Documentation_Update_with_Every_Change type="str">One strategy to adapt the documentation to a project&apos;s evolution is to document a change quickly after implement- ing it or requiring external developers to include documen- tation and tests with the code they contribute. Contributors C4, C8, and C10 ask external contributors to document their code contribution These three contributors want to ensure that the coverage of the code by the docu- mentation stays constant and that the contribution is well thought-out. For example, in the project of C9, many contributors review each code change so most usability or design problems are caught during the review phase and not while writing documentation. One advantage of requiring code contribution to be docu- mented is that it helps project maintainers to evaluate large contributions: &quot;I start with the documentation: if the doc- umentation is good I have fairly good confidence in the im- plementation. As users mentioned, one potential issue with requiring that all changes be documented is that developers might write content-free documentation: comprehensive policies established by C1 such as requiring a code example for each function help developers avoid this issue. </Documentation_Update_with_Every_Change><Use_of_a_Separate_Documentation_Team type="str">We observed that external contributors formed documentation teams and officially joined a project when the original code contributors believed that documentation was important to their project, but lacked motivation (i.e., they preferred to write code) or confidence in their docu- mentation skills. The first type (C5 and C7) is responsible for documenting everything, from the new features to in-depth tutorials. The other type (C12) is responsible for improving the documentation such as adding examples, polishing the writing style, or complet- ing the documentation, but code contributors are still re- sponsible for documenting their changes. All contributors who were in a documentation team mentioned that they sometimes acted as testers and reported issues with new features to the developers, but developers were not always receptive to their comments: &quot;somebody made a decision and it became that &apos;name&apos;, meanwhile some- one in the documentation had made  decision on what the name would be... In contrast, C12, who is part of the second type of team, mentioned that the development team usually let the docu- mentation team work on the terminology. </Use_of_a_Separate_Documentation_Team><Documentation_Updates_based_on_Questions type="str">One strategy used by contributors to leverage the com- munity is to consider questions asked on support channels (e.g., mailing list) to be a bug report on the documentation. But I am not aware of that. In our historical analysis of changes, we found that more than half of the clarifica- tion changes (102 out of 195) were about explicitly stating something that was implied, such as adding an extra step to a tutorial. A question raised by one individual on the mailing list might actually be asked by many more users. Many tricks are then used to evaluate if a question should be addressed by the documentation: was the question asked many times, is the answer provided by the community right or wrong, is the question addressed at all by the documentation, and is the question about an English-related issue and asked by a non-native English speaker? </Documentation_Updates_based_on_Questions><Summary type="str">SECTION TOO SHORT TO SUMMARIZE!</Summary><QUALITY_AND_CREDIBILITY type="str">and the credibility (are the findings trustworthy and do they reflect the participants&apos;, researchers&apos;, and read- ers&apos; experiences with a phenomenon?) of our study by rely- ing on three criteria proposed by Corbin and Strauss : fit, applicability, and sensitivity. We produced a four-page summary presenting a subset of the decisions we analyzed and we invited the 12 contrib- utors to review this summary to ensure that our findings resonated with their experience. There are only a few decisions that we did not analyze because we thought that they were less relevant to documentation (e.g., how to support users). To the best of our knowledge, this is the first study on the process taken by contributors to create and main- tain developer documentation. </QUALITY_AND_CREDIBILITY><RELATED_WORK type="str">Most of the related work on developer documentation has focused on studying how developers use documentation and devising techniques to document programs. They identified general kinds of questions such as finding out what features are provided by the framework and understanding how classes communicate together in the presence of inversion of control and subtle dependencies. Robillard conducted a survey and qualitative interviews in a study of how Microsoft developers learn APIs . For example, SpotWeb mines code examples found on the web to recommend frame- work hotspots, i.e., classes and methods that are frequently reused . Schfer et al. used a clustering technique to recover the main building blocks of a framework from client programs to build a representation of the framework that is easy to un- derstand by users . </RELATED_WORK><CONCLUSION type="str">Understanding how these decisions are made and what their consequences are can help researchers devise documen- tation techniques that are more suited to the documenta- tion process of open source projects and that alleviate the issues we identified. Addition of a URL to the documentation. When new sentences or domain-specific words were added to clarify an existing sentence, we considered the change to be part of the clarification category. This is often caused by SPAM, but incorrect or unclear addition by contributors can also cause a revert. The last column, Avg., presents an unweighted average of each category across the 10 projects: because we did not ana- lyze the same number of documents and revisions for each project, a weighted average would be heavily biased toward the documents with the most revisions. </CONCLUSION></root>